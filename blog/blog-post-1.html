<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Surviving the Titanic: My First Machine Learning Journey - LCC</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fragment+Mono:wght@400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../styles.css">
  <link rel="stylesheet" href="assets/blog-post.css">
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
</head>
<body>
  <header class="nav-header">
    <a href="../index.html" class="logo">LCC</a>
    <nav class="nav-links">
      <a href="../blog.html" class="nav-link">Blog</a>
      <a href="../contact.html" class="nav-link">Contact</a>
      <button id="theme-toggle" class="theme-toggle">
        <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"></path>
        </svg>
      </button>
    </nav>
    <button id="mobile-menu-button" class="mobile-menu-button">
      <svg width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7"></path>
      </svg>
    </button>
  </header>

  <main class="article-main">
    <header class="article-header">
      <div class="article-header-content">
        <nav class="breadcrumb">
          <a href="../blog.html" class="breadcrumb-link">Blog</a>
          <span class="breadcrumb-separator">/</span>
          <span class="breadcrumb-current">Surviving the Titanic: My First Machine Learning Journey</span>
        </nav>
        
        <div class="article-meta">
          <time class="article-date">August 13, 2025</time>
          <span class="article-category">Machine Learning</span>
          <span class="reading-time">8 min read</span>
        </div>
        
        <h1 class="article-title">Surviving the Titanic: My First Machine Learning Journey</h1>
        <p class="article-subtitle">From raw passenger data to predictive survival models — lessons from my first Kaggle challenge</p>
        
        <div class="article-tags">
          <span class="article-tag">Kaggle</span>
          <span class="article-tag">Data Science</span>
          <span class="article-tag">Machine Learning</span>
        </div>
      </div>
    </header>

    <article class="article-content">
      <div class="article-container">

        <section class="article-section">
          <p class="article-intro">
            This week I finished my first Kaggle machine learning project: the Titanic Survival Prediction challenge. It might be the “hello world” of data science, but for me it was a hands-on crash course in data cleaning, feature engineering, and model training.
          </p>
          <p>When I first opened the project, I imagined spending most of my time comparing different models and celebrating high accuracy scores. Instead, I quickly learned that the real work begins long before the model is built. This project became a crash course in the practical realities of machine learning, and it taught me lessons that I can already see translating into my work as a data analyst and marketing professional.</p>
        </section>

        <section class="article-section">
          <h2>Phase 1: The Iceberg Beneath the Surface – Data Cleaning</h2>
          <p>The phrase “data cleaning is 80% of the job” is something I had heard before, but now I truly understand it.</p>
          <p>The Titanic dataset looked simple at first glance: passenger details, ages, fares, and whether they survived. Once I started exploring it, I found missing ages, incomplete cabin information, and even missing embarkation points. There were also inconsistent data types, such as numerical fields stored as text, and categorical features that needed standardization.</p>
          <p>I filled missing ages using median values, encoded categorical variables like “Sex” and “Embarked,” and normalized continuous features to ensure they were on the same scale. This stage taught me that a model is only as good as the data it receives, and that careful preparation is the foundation of reliable predictions.</p>
        </section>

        <section class="article-section">
          <h2>Phase 2: Feature Engineering – Turning Raw Data into Predictive Power</h2>
          <p>Once the data was clean, I moved into feature engineering, which felt like uncovering hidden clues. The goal here was to create new variables that could help the model learn more effectively.</p>
          <ul class="article-list">
            <li><strong>Title extraction:</strong> Pulling out titles like “Mr”, “Miss”, and “Dr” from names provided social context that correlated with survival.</li>
            <li><strong>Family size:</strong> Combining the number of siblings/spouses and parents/children on board into a single variable revealed patterns in survival rates.</li>
            <li><strong>Cabin deck grouping:</strong> Mapping cabin numbers to decks gave location-based survival insights.</li>
          </ul>
          <p>This stage helped me appreciate that strong predictive performance often comes from well-thought-out features, not just sophisticated algorithms.</p>
        </section>

        <section class="article-section">
          <h2>Phase 3: Model Selection and Hyperparameter Tuning</h2>
          <p>With clean data and meaningful features, I began testing different models. I started with Logistic Regression as a baseline. Then I tried more complex models like Random Forest, Gradient Boosting, and XGBoost.</p>
          <p>I found that ensemble models like Random Forest and Gradient Boosting performed better once the features were optimized. I also used GridSearchCV to tune hyperparameters such as maximum tree depth, number of estimators, and learning rate. This fine-tuning improved accuracy and helped me understand how small adjustments can make a big difference in performance.</p>
        </section>

        <section class="article-section">
          <h2>Applying These Skills to My Career</h2>
          <ul class="article-list">
            <li><strong>Data cleaning:</strong> Mirrors preparing customer datasets with missing demographics, duplicates, and inconsistent records.</li>
            <li><strong>Feature engineering:</strong> Similar to creating business metrics like customer lifetime value or engagement scores.</li>
            <li><strong>Model selection and tuning:</strong> Relates to choosing the right predictive tools for tasks like churn prediction or campaign performance forecasting.</li>
          </ul>
          <p>This project showed me how machine learning can take me from descriptive analytics, where we explain what happened, to predictive analytics, where we anticipate what is likely to happen.</p>
        </section>

        <section class="article-section">
          <h2>Final Reflection</h2>
          <p>The Titanic project was more than a coding exercise. It was a complete learning experience in managing a machine learning workflow from start to finish. I discovered that success comes from a balance of technical skill, creative problem solving, and attention to detail.</p>
          <p>I now see machine learning as a valuable extension of my existing analytical toolkit. In marketing and data analysis, these skills can help transform large volumes of raw information into actionable insights that guide better business decisions.</p>
        </section>

        <footer class="article-footer">
          <div class="article-footer-content">
            <p class="article-footer-text">
              My first Kaggle project taught me that success in machine learning isn’t just about the model — it’s about the entire process, from data cleaning to deploying insights.
            </p>
          </div>
        </footer>
      </div>
    </article>
  </main>
</body>
</html>
